{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/Users/mattbaldree/Google Drive/smu/quantifying/QTW_14/QTW_14\r\n"
     ]
    }
   ],
   "source": [
    "import locale\n",
    "locale.setlocale(locale.LC_ALL, 'en_US')\n",
    "\n",
    "!pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "# flags\n",
    "PURGE_DATA = True"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "plan of attack\n",
    "\n",
    "- ~~download files in parallel~~\n",
    "- view a file\n",
    "- read files in parallel to csv format\n",
    "- convert to parquet format\n",
    "- read into df_p\n",
    "- work with df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table style=\"border: 2px solid white;\">\n",
       "<tr>\n",
       "<td style=\"vertical-align: top; border: 0px solid white\">\n",
       "<h3>Client</h3>\n",
       "<ul>\n",
       "  <li><b>Scheduler: </b>tcp://127.0.0.1:54761\n",
       "  <li><b>Dashboard: </b><a href='http://127.0.0.1:54762' target='_blank'>http://127.0.0.1:54762</a>\n",
       "</ul>\n",
       "</td>\n",
       "<td style=\"vertical-align: top; border: 0px solid white\">\n",
       "<h3>Cluster</h3>\n",
       "<ul>\n",
       "  <li><b>Workers: </b>4</li>\n",
       "  <li><b>Cores: </b>4</li>\n",
       "  <li><b>Memory: </b>10.31 GB</li>\n",
       "</ul>\n",
       "</td>\n",
       "</tr>\n",
       "</table>"
      ],
      "text/plain": [
       "<Client: scheduler='tcp://127.0.0.1:54761' processes=4 cores=4>"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# start Dask distributed client and print out stats\n",
    "from dask.distributed import Client\n",
    "c = Client()\n",
    "c"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "if PURGE_DATA:\n",
    "    # delete /data directory\n",
    "    import os\n",
    "    from shutil import rmtree\n",
    "\n",
    "    path = 'data'\n",
    "    if os.path.exists(path):\n",
    "        rmtree(path)\n",
    "    \n",
    "    # make /data if it doesn't exist\n",
    "    path = 'data'\n",
    "    if not os.path.exists(path):\n",
    "        os.mkdir(path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 36.4 s, sys: 10.5 s, total: 46.9 s\n",
      "Wall time: 9min 11s\n",
      "downloaded file: data/1987.csv , of size (MB): 127.2\n",
      "downloaded file: data/1988.csv , of size (MB): 501.0\n",
      "downloaded file: data/1989.csv , of size (MB): 486.5\n",
      "downloaded file: data/1990.csv , of size (MB): 509.2\n",
      "downloaded file: data/1991.csv , of size (MB): 491.2\n",
      "downloaded file: data/1992.csv , of size (MB): 492.3\n",
      "downloaded file: data/1993.csv , of size (MB): 490.8\n",
      "downloaded file: data/1994.csv , of size (MB): 501.6\n",
      "downloaded file: data/1995.csv , of size (MB): 530.8\n",
      "downloaded file: data/1996.csv , of size (MB): 533.9\n",
      "downloaded file: data/1997.csv , of size (MB): 540.3\n",
      "downloaded file: data/1998.csv , of size (MB): 538.4\n",
      "downloaded file: data/1999.csv , of size (MB): 552.9\n",
      "downloaded file: data/2000.csv , of size (MB): 570.2\n",
      "downloaded file: data/2001.csv , of size (MB): 600.4\n",
      "downloaded file: data/2002.csv , of size (MB): 530.5\n",
      "downloaded file: data/2003.csv , of size (MB): 626.7\n",
      "downloaded file: data/2004.csv , of size (MB): 669.9\n",
      "downloaded file: data/2005.csv , of size (MB): 671.0\n",
      "downloaded file: data/2006.csv , of size (MB): 672.1\n",
      "downloaded file: data/2007.csv , of size (MB): 702.9\n",
      "downloaded file: data/2008.csv , of size (MB): 689.4\n",
      "Number of files download: 22 for a total size (MB): 12029.214092999999\n"
     ]
    }
   ],
   "source": [
    "DOWNLOAD_ONE_FILE_ONLY = False\n",
    "\n",
    "if PURGE_DATA:\n",
    "    import urllib.request\n",
    "    import shutil\n",
    "    import bz2\n",
    "    \n",
    "    def download_file(baseurl, yr):\n",
    "        file_name = ''\n",
    "\n",
    "        url_of_data_file = baseurl%(yr)\n",
    "        file_name = 'data/%d.csv'%(yr)\n",
    "        size = 0\n",
    "\n",
    "        print('downloading', url_of_data_file, 'to', file_name)\n",
    "        decompressor = bz2.BZ2Decompressor()\n",
    "\n",
    "        # download file and decompress it\n",
    "        with urllib.request.urlopen(url_of_data_file) as response, open(file_name, 'wb') as out_file:\n",
    "                data = decompressor.decompress(response.read())\n",
    "                out_file.write(data)\n",
    "                size = len(data)\n",
    "                print('file size (MB)', locale.format('%.1f', size/1000000, grouping=True))\n",
    "\n",
    "        return(file_name, size)\n",
    "    \n",
    "    def print_files(files):\n",
    "        totalSize = 0        \n",
    "        for f in files:\n",
    "            size = f[1]/1000000\n",
    "            totalSize += size\n",
    "            print('downloaded file:', f[0], ', of size (MB):', \n",
    "                  locale.format('%.1f', size, grouping=True))\n",
    "            \n",
    "        print('Number of files downloaded:', len(files), 'for a total size (MB):', \n",
    "              locale.format('%.1f', totalSize, grouping=True))\n",
    "\n",
    "\n",
    "    if DOWNLOAD_ONE_FILE_ONLY:\n",
    "        # testing\n",
    "        download_file('http://stat-computing.org/dataexpo/2009/%d.csv.bz2', 1987)\n",
    "    else:    \n",
    "        # download airline data from 1987 to 2009\n",
    "        yrs = range(1987, 2009)\n",
    "        baseurl = 'http://stat-computing.org/dataexpo/2009/%d.csv.bz2'\n",
    "\n",
    "        from dask import delayed\n",
    "        download_file = delayed(download_file)\n",
    "\n",
    "        files = [download_file(baseurl, yr) for yr in yrs]\n",
    "        files = delayed(files)\n",
    "\n",
    "        %time files = files.compute()   \n",
    "      \n",
    "        print_files(files)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Click on Dashboard URL printed out above to see the distributed work.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
