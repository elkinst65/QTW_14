{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "<a id=toc></a>\n",
    "# MSDS 7333 - Week 14 Case Study: Analyzing Airline Flight Delays\n",
    "\n",
    "### Investigators\n",
    "- [Matt Baldree](mailto:mbaldree@smu.edu?subject=lab14)\n",
    "- [Ben Brock](bbrock@smu.edu?subject=lab14)\n",
    "- [Tom Elkins](telkins@smu.edu?subject=lab14)\n",
    "- [Austin Kelly](ajkelly@smu.edu?subject=lab14)\n",
    "\n",
    "\n",
    "<div style='margin-left:10%;margin-right:10%;margin-top:15px;background-color:#d3d3d3;padding:5px;'>\n",
    "    <h3>Instructions</h3>\n",
    "    <p>Work with the airline data set (use R or Python to manage out-of-core).</p>\n",
    "     <p>Answer the following questions by using the split-apply-combine technique</p>\n",
    "    <ol>\n",
    "        <li>Which airports are most likely to be delayed flying out of or into?</li>\n",
    "        <li>Which flights with same origin and destination are most likely to be delayed?</li>\n",
    "        <li>Can you regress how delayed a flight will be before it is delayed?</li>\n",
    "        <li>What are the most important features for this regression?\n",
    "            <ul>\n",
    "            <li>Remember to properly cross-validate models.\n",
    "            <li>Use meaningful evaluation criteria.\n",
    "            <li>Create at least one new feature variable for the regression.\n",
    "            </ul>\n",
    "            \n",
    "    </ol> \n",
    "            \n",
    "\n",
    "    <p>Report Sections:</p>\n",
    "    <ol>\n",
    "        <li>[Introduction](#introduction) <b>(5 points)</b></li>\n",
    "        <li>[Background](#background) <b>(10 points)</b></li>\n",
    "        <li>[Methods](#methods) <b>(30 points)</b></li>\n",
    "        <li>[Results](#results) <b>(30 points)</b></li>\n",
    "        <li>[Conclusion](#conclusion) <b>(5 points)</b></li>\n",
    "        <li>[Bibliography and Citation](#biblio) <b>(5 points)</b></li>\n",
    "        <li>[Code](#code) <b>(5 points)</b></li>\n",
    "    </ol>\n",
    "     <p>Other Grading Criterium:</p>\n",
    "    <ol>\n",
    "        <li>Grammar and Organization <b>(10 points)</b></li>\n",
    "    </ol>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "<a id='introduction'></a>\n",
    "## 1 - Introduction\n",
    "<div style='margin-left:10%;margin-right:10%;margin-top:15px;background-color:#d3d3d3;padding:10px;'>\n",
    "<h3>Introduction (<b>5 points total</b>)</h3>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "### Explain what  we will be working with and how we intend to approach the issue"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "For this case study, we are tasked with acquiring and combining airline data from 22 separate years of airline history. Once the data is downloaded, it will be parsed and appended to a data frame in which we will be able to determine the statistics of said data. With such a large amount of data, it will be notably difficult to be able to use conventional methods to aggregate and perform calculations with conventional methods. \n",
    "\n",
    "The data in question totals just over 123.5 Million records and sizes up to be about 14 Gigabytes **uncompressed** of just csv data. \n",
    "\n",
    "That's a lot of data.\n",
    "\n",
    "In order to be able to not only handle the data but also perform calculations over the dataframe, we will need to utilize more than just a single core of the (current) 4-core processors embedded within our machines. When more than a single processor core is utilized, we venture into the realm of parallel computing. As we parse and sift through the data, parallel computig allows for a rather novel idea: break the data down into even parts and process all three parts at the same time. Many titans of industry use platforms such as Hadoop Distributed File System (HDFS) to manage massive amounts of data relatively quickly with clusters of commodity servers. When a massive datafile comes through (in our case, 12-14 Gb), instead of just using a single core to process all of the data, we will use three cores to process 4-5 Gb of data _each_, leaving a spare core (the master) to manage all three cores.\n",
    "\n",
    "For this case study, we were met with many roadblocks such as software compatibility with hardware along with version control. We found it was quite difficult to manage older versions of R alongside the newest version of Python, all in the same Jupyter notebook. To minimize these roadblocks, our team utilized the Python 3.4 package [Dask](https://dask.pydata.org/en/latest/) along with Python 2.7's [Graphlab-Create](https://turi.com/). Once these processes were executed in their entirety, we decided to cross-validate our findings by generating an equivalent Javascript environment to independently test our findings. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "[&uarr; ToC](#toc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "<a id=\"background\"></a>\n",
    "## 2 - Background\n",
    "\n",
    "<div style='margin-left:10%;margin-right:10%;margin-top:15px;background-color:#d3d3d3;padding:10px;'>\n",
    "<h3>Background (<b>10 points total</b>)</h3>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "The dataset our group acquired was comprised of just over 123 Million records with 29 attributes. These attributes are described in this table:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "### Variable descriptions of original data set\n",
    "|Item|Name|Description|\n",
    "|:--:|:--|:--|\n",
    "|1|\tYear\t|1987-2008|\n",
    "|2|\tMonth\t|1-12|\n",
    "|3|\tDayofMonth\t|1-31|\n",
    "|4|\tDayOfWeek\t|1 (Monday) - 7 (Sunday)|\n",
    "|5|\tDepTime\t|actual departure time (local, hhmm)|\n",
    "|6|\tCRSDepTime\t|scheduled departure time (local, hhmm)|\n",
    "|7|\tArrTime\tactual |arrival time (local, hhmm)|\n",
    "|8|\tCRSArrTime\t|scheduled arrival time (local, hhmm)|\n",
    "|9|\tUniqueCarrier\t|unique carrier code|\n",
    "|10|\tFlightNum\t|flight number|\n",
    "|11|\tTailNum\tplane |tail number|\n",
    "|12|\tActualElapsedTime\t|in minutes|\n",
    "|13|\tCRSElapsedTime\t|in minutes|\n",
    "|14|\tAirTime\t|in minutes|\n",
    "|15|\tArrDelay\t|arrival delay, in minutes|\n",
    "|16|\tDepDelay\t|departure delay, in minutes|\n",
    "|17|\tOrigin\t|origin IATA airport code|\n",
    "|18|\tDest\t|destination IATA airport code|\n",
    "|19|\tDistance\t|in miles|\n",
    "|20|\tTaxiIn\t|taxi in time, in minutes|\n",
    "|21|\tTaxiOut\t|taxi out time in minutes|\n",
    "|22|\tCancelled\t|was the flight cancelled?|\n",
    "|23|\tCancellationCode\t|reason for cancellation (A = carrier, B = weather, C = NAS, D = security)|\n",
    "|24|\tDiverted\t|1 = yes, 0 = no|\n",
    "|25|\tCarrierDelay\t|in minutes|\n",
    "|26|\tWeatherDelay\t|in minutes|\n",
    "|27|\tNASDelay\t|in minutes|\n",
    "|28|\tSecurityDelay\t|in minutes|\n",
    "|29|\tLateAircraftDelay\t|in minutes|"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "The three most-important (and required) questions are:\n",
    "\n",
    "(click on each question to navigate to the section of the notebook)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "<li>[Q1.What airports have the most delayed departures and arrivals?](#Question1)</li> \n",
    "<li>[Q2. What flights are most frequently delayed with same origin and destination?](#Question2)</li>\n",
    "<li>[Q3. Can you predict a flight's delayed time in minutes?](#Question3)</li>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "While these questions seem obvious to us, it is important to clearly identify our intent of what we are looking to explore in order to discover an appropriate answer to the proper questions. \n",
    "\n",
    "First and foremost, we will want to investigate (using the basic aggregation functions) just which airports are the main culprits for delayed departures and which are subject to the late arrivals. It must be declared a flight is considered to be delayed if it leaves or arrives more than 15 minutes from it's scheduled time. Something to be investigated at a later date (when adequate resources are available) is whether or not the late departures influence the late arrivals more than the late arrivals affect the late departures.\n",
    "\n",
    "The second question begs investigation into whether or not there is a specific route plagued with said delays. With so many unique routes, it will be interesting to see whether or not one route really sticks out over the rest. Since our analysis is limited to our data, we will not be seeing mnay \"entire\" routes. This is attributed to the simple fact that many entire routes (e.g. New York to Los Angeles) are typically comprised of multiple sub-routes. Thus, we will be focusing on the routes which comprise the longer routes. \n",
    "\n",
    "With all of the data we have at our disposal, we will explore the possibility of being able to predict just _how_ delayed a flight will be based on the many factors involved. While we do have numerous factors to possibly influence the outcome of our predictions, there are also several factors outside of the scope of this study that will be considered to be confounding variables. One such variable is the weather of the locations involved. As difficult as it may be to predict the delay of a particular flight based on the day of the week coupled with the carrier, it will be far more difficult to predict exact snowfall along with wind speed for the area in question, ultimately grounding unsuspecting travelers. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "[&uarr; ToC](#toc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "<a id=\"methods\"></a>\n",
    "## 3 - Methods\n",
    "\n",
    "<div style='margin-left:10%;margin-right:10%;margin-top:15px;background-color:#d3d3d3;padding:10px;'>\n",
    "<h3>Methods (<b>30 points total</b>)</h3>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "### Disuss Dask approach and our decision to go this route"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# general stuff\n",
    "import locale\n",
    "# locale.setlocale(locale.LC_ALL, 'en_US')\n",
    "\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "pd.set_option('display.max_columns', None)\n",
    "pd.set_option('compute.use_bottleneck', True)\n",
    "pd.set_option('compute.use_numexpr', True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "from matplotlib import pyplot as plt\n",
    "%matplotlib inline\n",
    "plt.style.use('ggplot')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "import dask.dataframe as dd\n",
    "from dask import compute, persist\n",
    "from dask.distributed import Client, progress\n",
    "\n",
    "# !pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# flags\n",
    "\n",
    "PURGE_DATA = True"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "<div style='color:red'>\n",
    "<h3>&darr; consider turning the results of this into a screenshot of whatever machine we use to do our final pass. </h3></div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "tornado.application - ERROR - Exception in callback functools.partial(<function wrap.<locals>.null_wrapper at 0x0000022991DEC730>, <tornado.concurrent.Future object at 0x0000022991DE7518>)\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\austi\\Anaconda3\\lib\\site-packages\\bokeh\\server\\tornado.py\", line 437, in _start_async\n",
      "    signal.signal(signal.SIGTERM, self._sigterm)\n",
      "  File \"C:\\Users\\austi\\Anaconda3\\lib\\signal.py\", line 47, in signal\n",
      "    handler = _signal.signal(_enum_to_int(signalnum), _enum_to_int(handler))\n",
      "ValueError: signal only works in main thread\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\austi\\Anaconda3\\lib\\site-packages\\tornado\\ioloop.py\", line 604, in _run_callback\n",
      "    ret = callback()\n",
      "  File \"C:\\Users\\austi\\Anaconda3\\lib\\site-packages\\tornado\\stack_context.py\", line 275, in null_wrapper\n",
      "    return fn(*args, **kwargs)\n",
      "  File \"C:\\Users\\austi\\Anaconda3\\lib\\site-packages\\tornado\\ioloop.py\", line 619, in <lambda>\n",
      "    self.add_future(ret, lambda f: f.result())\n",
      "  File \"C:\\Users\\austi\\Anaconda3\\lib\\site-packages\\tornado\\concurrent.py\", line 237, in result\n",
      "    raise_exc_info(self._exc_info)\n",
      "  File \"<string>\", line 3, in raise_exc_info\n",
      "  File \"C:\\Users\\austi\\Anaconda3\\lib\\site-packages\\tornado\\gen.py\", line 270, in wrapper\n",
      "    result = func(*args, **kwargs)\n",
      "  File \"C:\\Users\\austi\\Anaconda3\\lib\\types.py\", line 248, in wrapped\n",
      "    coro = func(*args, **kwargs)\n",
      "  File \"C:\\Users\\austi\\Anaconda3\\lib\\site-packages\\bokeh\\server\\tornado.py\", line 439, in _start_async\n",
      "    self.exit(1)\n",
      "AttributeError: 'BokehTornado' object has no attribute 'exit'\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<table style=\"border: 2px solid white;\">\n",
       "<tr>\n",
       "<td style=\"vertical-align: top; border: 0px solid white\">\n",
       "<h3>Client</h3>\n",
       "<ul>\n",
       "  <li><b>Scheduler: </b>tcp://127.0.0.1:50358\n",
       "  <li><b>Dashboard: </b><a href='http://127.0.0.1:8787' target='_blank'>http://127.0.0.1:8787</a>\n",
       "</ul>\n",
       "</td>\n",
       "<td style=\"vertical-align: top; border: 0px solid white\">\n",
       "<h3>Cluster</h3>\n",
       "<ul>\n",
       "  <li><b>Workers: </b>4</li>\n",
       "  <li><b>Cores: </b>4</li>\n",
       "  <li><b>Memory: </b>2.53 GB</li>\n",
       "</ul>\n",
       "</td>\n",
       "</tr>\n",
       "</table>"
      ],
      "text/plain": [
       "<Client: scheduler='tcp://127.0.0.1:50358' processes=4 cores=4>"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# start Dask distributed client and print out stats\n",
    "\n",
    "c = Client()\n",
    "c"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# if loading data, then purge existing data directory.\n",
    "\n",
    "if PURGE_DATA:\n",
    "    # delete /data directory\n",
    "    from shutil import rmtree\n",
    "\n",
    "    path = 'data'\n",
    "    if os.path.exists(path):\n",
    "        rmtree(path)\n",
    "    \n",
    "    # make /data if it doesn't exist\n",
    "    path = 'data'\n",
    "    if not os.path.exists(path):\n",
    "        os.mkdir(path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 11min 3s\n",
      "downloaded file: data/1987.csv , of size (MB): 127.2\n",
      "downloaded file: data/1988.csv , of size (MB): 501.0\n",
      "downloaded file: data/1989.csv , of size (MB): 486.5\n",
      "downloaded file: data/1990.csv , of size (MB): 509.2\n",
      "downloaded file: data/1991.csv , of size (MB): 491.2\n",
      "downloaded file: data/1992.csv , of size (MB): 492.3\n",
      "downloaded file: data/1993.csv , of size (MB): 490.8\n",
      "downloaded file: data/1994.csv , of size (MB): 501.6\n",
      "downloaded file: data/1995.csv , of size (MB): 530.8\n",
      "downloaded file: data/1996.csv , of size (MB): 533.9\n",
      "downloaded file: data/1997.csv , of size (MB): 540.3\n",
      "downloaded file: data/1998.csv , of size (MB): 538.4\n",
      "downloaded file: data/1999.csv , of size (MB): 552.9\n",
      "downloaded file: data/2000.csv , of size (MB): 570.2\n",
      "downloaded file: data/2001.csv , of size (MB): 600.4\n",
      "downloaded file: data/2002.csv , of size (MB): 530.5\n",
      "downloaded file: data/2003.csv , of size (MB): 626.7\n",
      "downloaded file: data/2004.csv , of size (MB): 669.9\n",
      "downloaded file: data/2005.csv , of size (MB): 671.0\n",
      "downloaded file: data/2006.csv , of size (MB): 672.1\n",
      "downloaded file: data/2007.csv , of size (MB): 702.9\n",
      "downloaded file: data/2008.csv , of size (MB): 689.4\n",
      "Number of files downloaded: 22 for a total size (MB): 12029.2\n"
     ]
    }
   ],
   "source": [
    "# if loading data, download files and decompress them in parallel.\n",
    "\n",
    "DOWNLOAD_ONE_FILE_ONLY = False\n",
    "\n",
    "if PURGE_DATA:\n",
    "    import urllib.request\n",
    "    import shutil\n",
    "    import bz2\n",
    "    \n",
    "    def download_file(baseurl, yr):\n",
    "        file_name = ''\n",
    "\n",
    "        url_of_data_file = baseurl%(yr)\n",
    "        file_name = 'data/%d.csv'%(yr)\n",
    "        size = 0\n",
    "\n",
    "        print('downloading', url_of_data_file, 'to', file_name)\n",
    "        decompressor = bz2.BZ2Decompressor()\n",
    "\n",
    "        # download file and decompress it\n",
    "        with urllib.request.urlopen(url_of_data_file) as response, open(file_name, 'wb') as out_file:\n",
    "                data = decompressor.decompress(response.read())\n",
    "                out_file.write(data)\n",
    "                size = len(data)\n",
    "                print('file size (MB)', locale.format('%.1f', size/1000000, grouping=True))\n",
    "\n",
    "        return(file_name, size)\n",
    "    \n",
    "    def print_files(files):\n",
    "        totalSize = 0        \n",
    "        for f in files:\n",
    "            size = f[1]/1000000\n",
    "            totalSize += size\n",
    "            print('downloaded file:', f[0], ', of size (MB):', \n",
    "                  locale.format('%.1f', size, grouping=True))\n",
    "            \n",
    "        print('Number of files downloaded:', len(files), 'for a total size (MB):', \n",
    "              locale.format('%.1f', totalSize, grouping=True))\n",
    "\n",
    "\n",
    "    if DOWNLOAD_ONE_FILE_ONLY:\n",
    "        # testing\n",
    "        download_file('http://stat-computing.org/dataexpo/2009/%d.csv.bz2', 1988)\n",
    "    else:    \n",
    "        # download airline data from 1987 to 2009\n",
    "        yrs = range(1987, 2009)\n",
    "        baseurl = 'http://stat-computing.org/dataexpo/2009/%d.csv.bz2'\n",
    "\n",
    "        from dask import delayed\n",
    "        download_file = delayed(download_file)\n",
    "\n",
    "        files = [download_file(baseurl, yr) for yr in yrs]\n",
    "        files = delayed(files)\n",
    "\n",
    "        %time files = files.compute()   \n",
    "      \n",
    "        print_files(files)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "csv file format\n",
      "Loading data\\*.csv files\n",
      "Wall time: 523 ms\n",
      "year                 float64\n",
      "month                float64\n",
      "dayofmonth           float64\n",
      "dayofweek            float64\n",
      "deptime              float64\n",
      "crsdeptime           float64\n",
      "arrtime              float64\n",
      "crsarrtime           float64\n",
      "uniquecarrier         object\n",
      "flightnum            float64\n",
      "tailnum               object\n",
      "actualelapsedtime    float64\n",
      "crselapsedtime       float64\n",
      "airtime              float64\n",
      "arrdelay             float64\n",
      "depdelay             float64\n",
      "origin                object\n",
      "dest                  object\n",
      "distance             float64\n",
      "taxiin               float64\n",
      "taxiout              float64\n",
      "cancelled            float64\n",
      "cancellationcode      object\n",
      "diverted             float64\n",
      "carrierdelay         float64\n",
      "weatherdelay         float64\n",
      "nasdelay             float64\n",
      "securitydelay        float64\n",
      "lateaircraftdelay    float64\n",
      "dtype: object\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>year</th>\n",
       "      <th>month</th>\n",
       "      <th>dayofmonth</th>\n",
       "      <th>dayofweek</th>\n",
       "      <th>deptime</th>\n",
       "      <th>crsdeptime</th>\n",
       "      <th>arrtime</th>\n",
       "      <th>crsarrtime</th>\n",
       "      <th>uniquecarrier</th>\n",
       "      <th>flightnum</th>\n",
       "      <th>tailnum</th>\n",
       "      <th>actualelapsedtime</th>\n",
       "      <th>crselapsedtime</th>\n",
       "      <th>airtime</th>\n",
       "      <th>arrdelay</th>\n",
       "      <th>depdelay</th>\n",
       "      <th>origin</th>\n",
       "      <th>dest</th>\n",
       "      <th>distance</th>\n",
       "      <th>taxiin</th>\n",
       "      <th>taxiout</th>\n",
       "      <th>cancelled</th>\n",
       "      <th>cancellationcode</th>\n",
       "      <th>diverted</th>\n",
       "      <th>carrierdelay</th>\n",
       "      <th>weatherdelay</th>\n",
       "      <th>nasdelay</th>\n",
       "      <th>securitydelay</th>\n",
       "      <th>lateaircraftdelay</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1987.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>14.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>741.0</td>\n",
       "      <td>730.0</td>\n",
       "      <td>912.0</td>\n",
       "      <td>849.0</td>\n",
       "      <td>PS</td>\n",
       "      <td>1451.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>91.0</td>\n",
       "      <td>79.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>23.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>SAN</td>\n",
       "      <td>SFO</td>\n",
       "      <td>447.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1987.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>15.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>729.0</td>\n",
       "      <td>730.0</td>\n",
       "      <td>903.0</td>\n",
       "      <td>849.0</td>\n",
       "      <td>PS</td>\n",
       "      <td>1451.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>94.0</td>\n",
       "      <td>79.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>14.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>SAN</td>\n",
       "      <td>SFO</td>\n",
       "      <td>447.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1987.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>17.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>741.0</td>\n",
       "      <td>730.0</td>\n",
       "      <td>918.0</td>\n",
       "      <td>849.0</td>\n",
       "      <td>PS</td>\n",
       "      <td>1451.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>97.0</td>\n",
       "      <td>79.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>29.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>SAN</td>\n",
       "      <td>SFO</td>\n",
       "      <td>447.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1987.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>18.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>729.0</td>\n",
       "      <td>730.0</td>\n",
       "      <td>847.0</td>\n",
       "      <td>849.0</td>\n",
       "      <td>PS</td>\n",
       "      <td>1451.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>78.0</td>\n",
       "      <td>79.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-2.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>SAN</td>\n",
       "      <td>SFO</td>\n",
       "      <td>447.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1987.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>19.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>749.0</td>\n",
       "      <td>730.0</td>\n",
       "      <td>922.0</td>\n",
       "      <td>849.0</td>\n",
       "      <td>PS</td>\n",
       "      <td>1451.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>93.0</td>\n",
       "      <td>79.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>33.0</td>\n",
       "      <td>19.0</td>\n",
       "      <td>SAN</td>\n",
       "      <td>SFO</td>\n",
       "      <td>447.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     year  month  dayofmonth  dayofweek  deptime  crsdeptime  arrtime  \\\n",
       "0  1987.0   10.0        14.0        3.0    741.0       730.0    912.0   \n",
       "1  1987.0   10.0        15.0        4.0    729.0       730.0    903.0   \n",
       "2  1987.0   10.0        17.0        6.0    741.0       730.0    918.0   \n",
       "3  1987.0   10.0        18.0        7.0    729.0       730.0    847.0   \n",
       "4  1987.0   10.0        19.0        1.0    749.0       730.0    922.0   \n",
       "\n",
       "   crsarrtime uniquecarrier  flightnum tailnum  actualelapsedtime  \\\n",
       "0       849.0            PS     1451.0     NaN               91.0   \n",
       "1       849.0            PS     1451.0     NaN               94.0   \n",
       "2       849.0            PS     1451.0     NaN               97.0   \n",
       "3       849.0            PS     1451.0     NaN               78.0   \n",
       "4       849.0            PS     1451.0     NaN               93.0   \n",
       "\n",
       "   crselapsedtime  airtime  arrdelay  depdelay origin dest  distance  taxiin  \\\n",
       "0            79.0      NaN      23.0      11.0    SAN  SFO     447.0     NaN   \n",
       "1            79.0      NaN      14.0      -1.0    SAN  SFO     447.0     NaN   \n",
       "2            79.0      NaN      29.0      11.0    SAN  SFO     447.0     NaN   \n",
       "3            79.0      NaN      -2.0      -1.0    SAN  SFO     447.0     NaN   \n",
       "4            79.0      NaN      33.0      19.0    SAN  SFO     447.0     NaN   \n",
       "\n",
       "   taxiout  cancelled cancellationcode  diverted  carrierdelay  weatherdelay  \\\n",
       "0      NaN        0.0              NaN       0.0           NaN           NaN   \n",
       "1      NaN        0.0              NaN       0.0           NaN           NaN   \n",
       "2      NaN        0.0              NaN       0.0           NaN           NaN   \n",
       "3      NaN        0.0              NaN       0.0           NaN           NaN   \n",
       "4      NaN        0.0              NaN       0.0           NaN           NaN   \n",
       "\n",
       "   nasdelay  securitydelay  lateaircraftdelay  \n",
       "0       NaN            NaN                NaN  \n",
       "1       NaN            NaN                NaN  \n",
       "2       NaN            NaN                NaN  \n",
       "3       NaN            NaN                NaN  \n",
       "4       NaN            NaN                NaN  "
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# print the head of a csv file\n",
    "\n",
    "print('csv file format')\n",
    "# !head data/1987.csv\n",
    "\n",
    "# load csv files into a dataframe in parallel\n",
    "\n",
    "filename = os.path.join('data', '*.csv')\n",
    "print('Loading', filename, 'files')\n",
    "\n",
    "import dask.dataframe as dd\n",
    "%time df_csv = dd.read_csv(filename, assume_missing=True, \\\n",
    "                           dtype={'TailNum':np.object, 'CancellationCode':np.object}, \\\n",
    "                           storage_options={'anon': True}).rename(columns=str.lower)\n",
    "\n",
    "print(df_csv.dtypes)\n",
    "df_csv.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# drop columns we don't need or want\n",
    "df_csv = df_csv.drop(['tailnum', 'actualelapsedtime', 'crselapsedtime', 'airtime', \\\n",
    "             'taxiin', 'taxiout', 'cancelled', 'cancellationcode', \\\n",
    "             'diverted', 'carrierdelay', 'weatherdelay', 'nasdelay', \\\n",
    "             'securitydelay', 'lateaircraftdelay'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# categorize appropriate columns\n",
    "\n",
    "object_columns = ['uniquecarrier', 'origin', 'dest', 'year', 'month', 'dayofmonth', 'dayofweek']\n",
    "for i in object_columns:\n",
    "    df_csv[i] = df_csv[i].astype('category')\n",
    "\n",
    "df_csv = df_csv.categorize()\n",
    "df_csv.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'df_csv' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-1-166f82814833>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[1;31m# length of dataframe\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mnumber_of_items\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdf_csv\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0mlocale\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'%d'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnumber_of_items\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mgrouping\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'df_csv' is not defined"
     ]
    }
   ],
   "source": [
    "# length of dataframe\n",
    "\n",
    "number_of_items = len(df_csv)\n",
    "locale.format('%d', number_of_items, grouping=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# Top 10 origin airports\n",
    "\n",
    "origin_counts = df_csv.origin.value_counts().head(10)\n",
    "print('Top origin airports')\n",
    "print(origin_counts)\n",
    "\n",
    "origin_counts.plot(kind='barh', figsize=(8,4), title='Top Origin Airports')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "[&uarr; ToC](#toc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "<a id=Question1></a>\n",
    "## Q1. What airports have the most delayed departures and arrivals?\n",
    "\n",
    "A flight is delayed if it leaves or arrives more than 15 minutes after its scheduled time."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# Filter departure flights\n",
    "\n",
    "df_delayed_departure = df_csv[df_csv.depdelay > 15]\n",
    "delayed_counts = df_delayed_departure.origin.value_counts().head(10)\n",
    "print('Top delayed origin airports')\n",
    "print(delayed_counts)\n",
    "\n",
    "delayed_counts.plot(kind='barh', figsize=(8,4), title='Top Delayed Origin Airports')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Filter arrival flights\n",
    "\n",
    "df_delayed_arrival = df_csv[df_csv.arrdelay > 15]\n",
    "delayed_counts = df_delayed_arrival.dest.value_counts().head(10)\n",
    "print('Top delayed destination airports')\n",
    "print(delayed_counts)\n",
    "\n",
    "delayed_counts.plot(kind='barh', figsize=(8,4), title='Top Delayed Destination Airports')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "[&uarr; ToC](#toc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "<a id = Question2></a>\n",
    "## Q2. What flights are most frequently delayed with same origin and destination?\n",
    "\n",
    "A flight is delayed if it leaves or arrives more than 15 minutes after its scheduled time."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# Filter the dataset to delayed flights\n",
    "\n",
    "df_filtered = df_csv.loc[(df_csv.arrdelay > 15) or (df_csv.depdelay > 15)].compute()\n",
    "df_filtered.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# categorize appropriate columns\n",
    "\n",
    "object_columns = ['origin', 'dest', 'flightnum']\n",
    "for i in object_columns:\n",
    "    df_filtered[i] = df_filtered[i].astype('category')\n",
    "\n",
    "df_filtered = df_filtered.categorize()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "df_filtered.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Group filtered dataset by origin, dest, and flightnum\n",
    "\n",
    "grp = df_filtered.groupby(['origin', 'dest', 'flightnum']) \\\n",
    ".flightnum.count().reset_index(name='count').sort_values(['count'], ascending=False)\n",
    "\n",
    "grp.head(15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Plot results\n",
    "\n",
    "grp.head(15).plot(kind='barh', figsize=(8,4), \\\n",
    "                  title='Top Delayed Flights with Same Origin and Destination Airports')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "[&uarr; ToC](#toc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "<a id=Question3></a>\n",
    "## Q3. Can you predict a flight's delayed time in minutes?\n",
    "\n",
    "Create a prediction model to predict flight delays. Dependent features like weather were not added because you don't know the weather accurately for the day. A new feature was added named `hdays` to indicate how many days the flight was from a holiday. Holidays have a significant impact on travel. Other key features might be helpful, but time did not permit further exploration.\n",
    "\n",
    "[&darr; we should probably add this to the end &darr;](#biblio)\n",
    "\n",
    "The work is borrowed from \n",
    "> `https://jessesw.com/Air-Delays/`,  \n",
    "> `https://gist.github.com/mrocklin/19c89d78e34437e061876a9872f4d2df`, and \n",
    "> `https://github.com/dmlc/xgboost/blob/master/demo/guide-python/sklearn_examples.py`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# Function to determine the difference between flight date and nearest holiday.\n",
    "# see https://jessesw.com/Air-Delays/\n",
    "\n",
    "from pandas.tseries.holiday import USFederalHolidayCalendar\n",
    "cal = USFederalHolidayCalendar()\n",
    "holidays = cal.holidays(start='1987-01-01', end='2008-12-31').to_pydatetime()\n",
    "\n",
    "from datetime import date, datetime, timedelta\n",
    "\n",
    "def days_until_holiday(d):\n",
    "    ans = timedelta(100000)\n",
    "    for i in range(len(holidays)):\n",
    "        candidate = abs(holidays[i]-d)\n",
    "        if candidate < ans:\n",
    "            ans = candidate\n",
    "    return(float(ans.days))\n",
    "\n",
    "#assert(days_until_holiday(datetime(2001, 1, 1))==0)\n",
    "#assert(days_until_holiday(datetime(2009, 1, 1))==7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# random sample of data (features)\n",
    "df = df_csv.sample(frac=0.05)\n",
    "\n",
    "# drop rows with NaN\n",
    "prev_count = len(df)\n",
    "df = df.dropna()\n",
    "number_of_items = len(df)\n",
    "print('dropped %s percent of rows with NA' % locale.format('%.2f', prev_count/number_of_items))\n",
    "\n",
    "# target data\n",
    "y = df.depdelay\n",
    "\n",
    "df = df.drop(['depdelay'], axis=1)\n",
    "\n",
    "df, y = persist(df, y)\n",
    "progress(df, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# Using apply is slow. Need to see if there is a faster way.\n",
    "\n",
    "# create days from nearest holiday column\n",
    "df_csv['hdays'] = df_csv.apply(lambda r: days_until_holiday(datetime(int(r.year), int(r.month), int(r.dayofmonth))),\n",
    "                               meta=float, axis=1)\n",
    "\n",
    "# convert scheduled time into hrs\n",
    "df_csv['depthr'] = df_csv.apply(lambda r: np.trunc(r.crsdeptime / 100.), meta='category', axis=1)\n",
    "df_csv['arrhr'] = df_csv.apply(lambda r: np.trunc(r.crsarrtime / 100.), meta='category', axis=1)\n",
    "df_csv.depthr = df_csv.depthr.astype('category')\n",
    "df_csv.arrhr = df_csv.arrhr.astype('category')\n",
    "\n",
    "df_csv.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# drop columns we don't need or want\n",
    "df_csv = df_csv.drop(['deptime', 'arrtime', 'flightnum', 'crsarrtime', 'crsdeptime'], axis=1)\n",
    "df_csv.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# categorize appropriate columns\n",
    "\n",
    "object_columns = ['uniquecarrier', 'origin', 'dest', 'year', 'month', 'dayofmonth', 'dayofweek']\n",
    "for i in object_columns:\n",
    "    df[i] = df[i].astype('category')\n",
    "\n",
    "df = df.categorize()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "df.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# random sample of data (features)\n",
    "df = df_csv.sample(frac=0.2)\n",
    "\n",
    "# drop rows with NaN\n",
    "prev_count = len(df)\n",
    "df = df.dropna()\n",
    "number_of_items = len(df)\n",
    "print('dropped %s percent of rows with NA' % locale.format('%.2f', prev_count/number_of_items))\n",
    "\n",
    "# target data\n",
    "y = df.depdelay\n",
    "\n",
    "df = df.drop(['depdelay'], axis=1)\n",
    "\n",
    "df, y = persist(df, y)\n",
    "progress(df, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "y.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "## One hot encode"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "X = dd.get_dummies(df.categorize())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "X.describe().compute()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "len(X.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "X.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "[&uarr; ToC](#toc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "## Split and Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "data_train, data_test = X.random_split([0.9, 0.1], random_state=1234)\n",
    "labels_train, labels_test = y.random_split([0.9, 0.1], random_state=1234)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "## Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# from sklearn.preprocessing import StandardScaler\n",
    "# scaler = StandardScaler()\n",
    "# scaler.fit(data_train)\n",
    "# data_train = scaler.transform(data_train)\n",
    "# data_test = scaler.transform(data_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "from sklearn.linear_model import BayesianRidge\n",
    "model = BayesianRidge()\n",
    "model.fit(data_train, labels_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# This cell was interrupted by keyboard. Likely where we're going to leave it for the night.\n",
    "from sklearn.linear_model import Lasso\n",
    "model = Lasso(alpha=0.1)\n",
    "model.fit = delayed(model.fit)\n",
    "model.fit(data_train, labels_train).compute()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "from sklearn.linear_model import SGDRegressor\n",
    "\n",
    "model = SGDRegressor(random_state = 0) \n",
    "model.fit(data_train, labels_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "from sklearn.linear_model import Ridge\n",
    "model = Ridge(alpha=1.0)\n",
    "model.fit = delayed(model.fit)\n",
    "model.fit(data_train, labels_train).compute()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import mean_absolute_error\n",
    "    \n",
    "y_true, y_pred = labels_test, model.predict(data_test)\n",
    "    \n",
    "print('Mean absolute error of SGD regression was:')\n",
    "print(locale.format('%.1f', mean_absolute_error(y_true, y_pred), grouping=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "### Discuss graphlab create approach"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "### Alternate Approach with Javascript\n",
    "\n",
    "We explored various options for processing the data. One method we explored was using Javascript to mine the basic elements from the data as each record was read from each file.  The core object contained COUNT, MIN, MAX, SUM, and SUMSQ (sum of squares) properties.  Each variable of interest was instantiated as a core object, with the collection of variables being a FLTSTATS object.  Various groups of interest were then created as instantiations of the FLTSTATS object.  The end result was a Javascript object with the components necessary for computing basic statistics for all variables of interest in a variety of groupings:\n",
    "\n",
    "* byYear[1987-2008]\n",
    "* byYear[1987-2008].byMonth[1-12]\n",
    "* byYear[1987-2008].byMonth[1-12].byDate[1-31]\n",
    "* byYear[1987-2008].byMonth[1-12].byWeekday[1-7]\n",
    "* byYear[1987-2008].byDay[1-366]\n",
    "* byYear[1987-2008].byWeekday[1-7]\n",
    "* byYear[1987-2008].byWeek[1-53]\n",
    "* byYear[1987-2008].byWeek[1-53].byWeekday[1-7]\n",
    "* byMonth[1-12]\n",
    "* byMonth[1-12].byDate[1-31]\n",
    "* byMonth[1-12].byWeekday[1-7]\n",
    "* byWeek[1-53]\n",
    "* byWeek[1-53].byWeekday[1-7]\n",
    "* byWeekday[1-7]\n",
    "* byWeekday[1-7].byHour[0-24]\n",
    "* byDay[1-366]\n",
    "* byDate[1-31]\n",
    "* byHour[0-24]\n",
    "* byCarrier[]\n",
    "* byCarrier[].byYear[1987-2008]\n",
    "* byCarrier[].byYear[1987-2008].byMonth[1-12]\n",
    "* byCarrier[].byMonth[1-12]\n",
    "* byCarrier[].byMonth[1-12].byDate[1-31]\n",
    "* byCarrier[].byDay[1-366]\n",
    "* byCarrier[].byDate[1-31]\n",
    "\n",
    "Each element in this structure is a core object updated as the record were read from the source files.  We could then compute means, variances, standard deviations, standard errors, and confidence intervals for the means for any of the above groupings.\n",
    "\n",
    "We then attempted to answer as many of the questions posed in the case study as we could."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "<a id=\"results\"></a>\n",
    "## 4 - Results\n",
    "\n",
    "<div style='margin-left:10%;margin-right:10%;margin-top:15px;background-color:#d3d3d3;padding:10px;'>\n",
    "<h3>Results (<b>30 points total</b>)</h3>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "### Discuss results of Dask"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "### Discuss results of gl-create"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "### Results from Javascript Data Mining\n",
    "\n",
    "#### Question 3 - How many flights per day of the week?\n",
    "<img src=\"charts\\Q3.png\">\n",
    "* Saturdays had the least number of flights\n",
    "* Mondays had the most number of flights\n",
    "\n",
    "#### Question 4 - For each year, how many flights per day of the week?\n",
    "<img src=\"charts\\Q4.png\">\n",
    "* 1987 contained data only for Oct-Dec, so those numbers are small\n",
    "* We see the general trend of increasing flights as the years increased\n",
    "* We see the low numbers for Saturday flights indicated from Question 3\n",
    "* We see the drastic decline in 2002 as a result of 9/11\n",
    "* We see the drop in 2008 due to economic decline\n",
    "\n",
    "#### Question 5 - For each year, how many tail numbers are \"NA\"?\n",
    "<img src=\"charts\\Q5.png\">\n",
    "* Low count in 1987 because of the truncated reporting (Oct-Dec)\n",
    "* From 1995 on, all tail numbers were reported\n",
    "\n",
    "#### Question 6 - Which year had the greatest proportion of late flights?\n",
    "<img src=\"charts\\Q6.png\">\n",
    "* Even though 1987 only covered the final quarter of the year, it had the highest proportion of late arrivals than any other year (61.6%)\n",
    "* 2003 had the smallest proportion of late arrivals (37.6%)\n",
    "* 2002 had the greatest proportion of early arrivals (56%)\n",
    "* 2001 had the greatest proportion of on-time arrivals (8%)\n",
    "\n",
    "#### Question 7 - Which flight day is best for minimizing departure delays? Which time of day?\n",
    "<img src=\"charts\\Q7B.png\">\n",
    "* This data is grouped by day of year\n",
    "  * The winter holiday period had the greatest mean departure delays (approaching 20 minutes)\n",
    "  * There is also a spike during the middle of summer\n",
    "  * Fall is a good time of year to travel\n",
    "  \n",
    "<img src=\"charts\\Q7D.png\">\n",
    "* This data is grouped by day of month\n",
    "  * It appears that the 7th of the month had the smallest mean departure delay (about 7 minutes)\n",
    "  * The 22nd of the month had the largest mean departure delay (over 9 minutes)\n",
    "  \n",
    "<img src=\"charts\\Q7F.png\">\n",
    "* This data is grouped by day of the week\n",
    "  * Tuesdays had the smallest mean departure delay (6.5 minutes), followed closely by Saturdays\n",
    "  * Fridays had the largest mean departure delay (almost 10 minutes)\n",
    "  \n",
    "<img src=\"charts\\Q7H.png\">\n",
    "* This data is grouped by hour of the day\n",
    "  * 7AM had the smallest mean departure delay (over 2 minutes), and we see the delay steadily increase as the day progresses\n",
    "  * 10PM (2200 hrs) had the highest consistent mean departure delay (over 13 minutes)\n",
    "  * The large confidence interval for 24 is due to the fact that a few departures were listed as hour 24 instead of hour 00\n",
    "\n",
    "#### Question 8 - Which is the best day of the week to fly?\n",
    "<img src=\"charts\\Q8.png\">\n",
    "* Saturdays had the smallest percentage of late arrivals (41.7%) and the greatest percentage of early arrivals (52.3%)\n",
    "* Friday had the greatest percentage of late arrivals (51.3%) and the smallest percentage of early arrivals (42.4%)\n",
    "\n",
    "#### Question 9 - Which is the best day of the month to fly?\n",
    "<img src=\"charts\\Q9.png\">\n",
    "* The 31st of the month had the smallest percentage of late arrivals (44.8%) and the highest percentage of early arrivals (49%)\n",
    "* The 22nd of the month had the highest percentage of late arrivals (49.1%)\n",
    "\n",
    "#### Question 10 - Are flights given more time to reach their destination in later years?\n",
    "For this question, we looked at the ratio of the scheduled duration to the distance travelled.  If this ratio increases, then more time is given to the scheduled duration for the same distance.\n",
    "\n",
    "<img src=\"charts\\Q10A.png\">\n",
    "* There appears to be a spike around 1990, but a return to a lower and consistent value after that period\n",
    "* There are many records with no data\n",
    "\n",
    "We then looked at year and month to see if the spike could be explained better.\n",
    "<img src=\"charts\\Q10B.png\">\n",
    "* We see an increase in the winter of 1989-1990 (Nov-Feb)\n",
    "* There is no other indication that scheduled duration increased in later years\n",
    "\n",
    "#### Question 14 - How much does weather delay contribute to arrival delay?\n",
    "<img src=\"charts\\Q14A.png\">\n",
    "* Overall, weather accounts for only about 3% of total arrival delay\n",
    "* September has the highest percentage (over 4%)\n",
    "* March and April have the smallest percentage (about 2.5%)\n",
    "\n",
    "Weather is only one contributor to arrival delay, so we plotted the other contributors specified in the data\n",
    "<img src=\"charts\\Q14B.png\">\n",
    "* In addition to increased weather delays, September also seems to be the month in which the other factors also increase.\n",
    "* Security delays contribute only a fraction of a percentage to overall arrival delay\n",
    "\n",
    "We were also interested in looking at some metrics for specific air carriers\n",
    "\n",
    "#### Question: What is the average arrival/departure delay per carrier?\n",
    "<img src=\"charts\\C1.png\">\n",
    "* Hawaiian Airlines (HA) had mean delays below 0!\n",
    "* Aloha Airlines (AQ) had mean delays between 1-2 minutes\n",
    "* Mean arrival delay for all carriers was 7.6 minutes\n",
    "* Mean departure delay for all carriers was 10.45 minutes\n",
    "* Eastern Airlines (EA) had the largest mean departure delay (over 35 minutes)\n",
    "\n",
    "#### Question: Which carrier had the most/least cancellations/diverts?\n",
    "<img src=\"charts\\C2.png\">\n",
    "* Because of the wide range in results, we used a logarithmic scale for the y-axis\n",
    "* Aloha Airlines (AQ) had the least number of diverts (about 40), with American Airlines (AA) having the most (over 40,000!)\n",
    "* Pacific Southwest Airlines (PS) had the least number of cancellations (just over 1100), and United Airlines (UA) had the most (nearly 300,000!)\n",
    "* The mean number of diverts is just below 10,000\n",
    "* The mean number of cancellations is just over 90,000\n",
    "\n",
    "#### Question: Which carriers had the best/worst arrival delays?\n",
    "<img src=\"charts\\C3.png\">\n",
    "* Hawaiian Airlines (HA) had the smallest percentage of late arrivals (24.9%) and the highest percentage of early arrivals (70.4%)\n",
    "* Piedmont Aviation (PI) had the most late arrivals (66.8%)\n",
    "* Midway Airlines (ML(1)) had the best on-time record at 12.7%\n",
    "\n",
    "#### Question: Which carriers had the best/worst departure delays?\n",
    "<img src=\"charts\\C4.png\">\n",
    "* Hawaiian Airlines (HA) also had the smallest percentage of late departures (17.4%) and the highest percentage of early departures (77.7%)\n",
    "* Eastern Airlines (EA) and Midway Airlines (ML(1)) had the best on-time departure percentage (76.5% and 76.2% respectively)\n",
    "* Piedmont Aviation (PI) had the highest percentage of late departures (63.9%), which may have contributed to their high late arrival percentages."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "### Talk about how they all tie in (cross validation)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "[&uarr; ToC](#toc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "<a id=\"conclusion\"></a>\n",
    "## 5 - Conclusion\n",
    "\n",
    "<div style='margin-left:10%;margin-right:10%;margin-top:15px;background-color:#d3d3d3;padding:10px;'>\n",
    "<h3>Conclusion (<b>5 points total</b>)</h3>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "### what did we find and how did we answer all of the questions? "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "[&uarr; ToC](#toc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "<a id=\"biblio\"></a>\n",
    "## 6 - Bibliography and Citation\n",
    "\n",
    "<div style='margin-left:10%;margin-right:10%;margin-top:15px;background-color:#d3d3d3;padding:10px;'>\n",
    "<h3>Bibliography and Citation (<b>5 points total</b>)</h3>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "[&uarr; ToC](#toc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "<a id=\"code\"></a>\n",
    "## 7 - Code\n",
    "\n",
    "<div style='margin-left:10%;margin-right:10%;margin-top:15px;background-color:#d3d3d3;padding:10px;'>\n",
    "<h3>Code (5 points)</h3>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "[&uarr; ToC](#toc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
